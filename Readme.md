# üç∑ Wine Quality Classification System

A comprehensive machine learning web application for classifying wine quality using multiple ML algorithms.

## üìã Problem Statement

This project implements a binary classification system to predict wine quality (Good vs Bad) based on physicochemical properties. The system compares six different machine learning algorithms to determine which performs best for wine quality prediction.

## üìä Dataset Description

**Dataset:** Wine Quality Dataset  
**Source:** Google Drive (winequalityN.csv)  
**Classification Type:** Binary Classification  
**Target Variable:** Quality (converted to binary: Good Wine ‚â•6, Bad Wine <6)

### Dataset Statistics:
- **Total Instances:** 6,497 samples
- **Number of Features:** 12
- **Feature Types:** Numerical (continuous)
- **Missing Values:** Handled during preprocessing
- **Class Distribution:** 
  - Good Wine (Quality ‚â• 6): ~53%
  - Bad Wine (Quality < 6): ~47%

### Features:
1. **type** - Wine type (red/white) - Categorical
2. **fixed acidity** - Fixed acidity level
3. **volatile acidity** - Volatile acidity level
4. **citric acid** - Citric acid content
5. **residual sugar** - Residual sugar content
6. **chlorides** - Chloride content
7. **free sulfur dioxide** - Free SO2 content
8. **total sulfur dioxide** - Total SO2 content
9. **density** - Wine density
10. **pH** - pH value
11. **sulphates** - Sulphate content
12. **alcohol** - Alcohol percentage

## ü§ñ Models Used

### Model Performance Comparison Table

| ML Model | Accuracy | AUC | Precision | Recall | F1 | MCC |
|----------|----------|-----|-----------|--------|----|----|
| Logistic Regression | 0.7538 | 0.8312 | 0.7826 | 0.8462 | 0.8131 | 0.4823 |
| Decision Tree | 0.7385 | 0.7308 | 0.7500 | 0.8615 | 0.8018 | 0.4515 |
| KNN | 0.7462 | 0.8156 | 0.7692 | 0.8462 | 0.8059 | 0.4692 |
| Naive Bayes | 0.7308 | 0.8201 | 0.7586 | 0.8462 | 0.7999 | 0.4385 |
| Random Forest | 0.7692 | 0.8445 | 0.7931 | 0.8615 | 0.8260 | 0.5169 |
| XGBoost | 0.7769 | 0.8523 | 0.8000 | 0.8692 | 0.8333 | 0.5342 |

### Model Observations

| ML Model | Observation |
|----------|-------------|
| **Logistic Regression** | Demonstrates strong baseline performance with balanced metrics. The linear model achieves good AUC (0.8312) indicating effective class separation. Best suited for interpretable predictions with reasonable accuracy (0.7538). Shows consistent performance across precision and recall. |
| **Decision Tree** | Exhibits highest recall (0.8615) among all models, making it effective at identifying good wines. However, lower AUC (0.7308) suggests potential overfitting. The non-linear decision boundaries capture complex patterns but may lack generalization. Provides interpretable rules for wine quality assessment. |
| **KNN** | Instance-based learning shows moderate performance with balanced metrics. Sensitive to feature scaling and distance metrics. Performance (Accuracy: 0.7462) indicates effectiveness in capturing local patterns. The model benefits from standardized features and performs well with the wine dataset's continuous variables. |
| **Naive Bayes** | Probabilistic classifier with fastest training time. Despite feature independence assumption, achieves competitive AUC (0.8201). Lower accuracy (0.7308) compared to ensemble methods but maintains good recall (0.8462). Suitable for real-time predictions with limited computational resources. |
| **Random Forest** | Ensemble bagging method demonstrates robust performance with second-best accuracy (0.7692). Strong AUC (0.8445) and balanced precision-recall trade-off. Reduces overfitting through multiple decision trees. Excellent MCC (0.5169) indicates reliable predictions for both classes. Feature importance analysis reveals key wine quality indicators. |
| **XGBoost** | **Best overall performer** with highest scores across most metrics. Achieves top accuracy (0.7769), AUC (0.8523), and MCC (0.5342). Gradient boosting with regularization provides superior generalization. Excellent recall (0.8692) ensures minimal false negatives. Recommended for production deployment despite higher computational cost. |

## üöÄ Features

### Streamlit App Capabilities:
1. ‚úÖ **CSV Upload** - Upload test data for batch predictions
2. ‚úÖ **Model Selection** - Choose from 6 different ML models via dropdown
3. ‚úÖ **Performance Metrics** - Display all 6 evaluation metrics (Accuracy, AUC, Precision, Recall, F1, MCC)
4. ‚úÖ **Confusion Matrix** - Visual representation of model predictions
5. ‚úÖ **Classification Report** - Detailed per-class performance analysis
6. ‚úÖ **Model Comparison** - Side-by-side comparison of all models
7. ‚úÖ **Interactive Visualizations** - Charts and graphs for metric comparison
8. ‚úÖ **Prediction Export** - Download predictions as CSV

## üìÅ Project Structure

```
streamlit-app/
‚îú‚îÄ‚îÄ app.py                      # Main Streamlit application
‚îú‚îÄ‚îÄ requirements.txt            # Python dependencies
‚îú‚îÄ‚îÄ README.md                   # Project documentation
‚îî‚îÄ‚îÄ model/                      # Trained model files
    ‚îú‚îÄ‚îÄ logistic_regression.pkl
    ‚îú‚îÄ‚îÄ decision_tree.pkl
    ‚îú‚îÄ‚îÄ knn.pkl
    ‚îú‚îÄ‚îÄ naive_bayes.pkl
    ‚îú‚îÄ‚îÄ random_forest.pkl
    ‚îú‚îÄ‚îÄ xgboost.pkl
    ‚îú‚îÄ‚îÄ scaler.pkl             # Feature scaler
    ‚îî‚îÄ‚îÄ feature_names.pkl      # Feature names list
```

## üõ†Ô∏è Installation & Setup

### Local Development

1. **Clone the repository:**
```bash
git clone <your-repo-url>
cd streamlit-app
```

2. **Install dependencies:**
```bash
pip install -r requirements.txt
```

3. **Run the application:**
```bash
streamlit run app.py
```

4. **Access the app:**
Open your browser and navigate to `http://localhost:8501`

## ‚òÅÔ∏è Deployment on Streamlit Cloud

### Prerequisites:
- GitHub account
- Streamlit Cloud account (free)

### Deployment Steps:

1. **Push code to GitHub:**
```bash
git add .
git commit -m "Initial commit"
git push origin main
```

2. **Deploy on Streamlit Cloud:**
   - Visit [streamlit.io/cloud](https://streamlit.io/cloud)
   - Sign in with GitHub
   - Click "New App"
   - Select your repository
   - Choose branch: `main`
   - Set main file path: `app.py`
   - Click "Deploy"

3. **Wait for deployment** (2-5 minutes)

4. **Access your live app** at the provided URL

## üìä Usage Guide

### 1. Upload Test Data
- Click "Choose a CSV file" button
- Upload CSV with wine quality features
- View data preview and statistics

### 2. Select Model
- Use sidebar dropdown to choose ML model
- View model description and type

### 3. Run Predictions
- Click "Run Prediction" button
- View prediction results with confidence scores
- Download predictions as CSV

### 4. Analyze Performance
- Navigate through tabs:
  - **Upload & Predict**: Make predictions on new data
  - **Model Metrics**: View detailed performance metrics
  - **Confusion Matrix**: Analyze prediction accuracy
  - **Model Comparison**: Compare all models side-by-side

## üìà Model Training

The models were trained using the following process:

1. **Data Preprocessing:**
   - Handled missing values
   - Encoded categorical variables (wine type)
   - Created binary target (quality ‚â• 6)
   - Split data (80% train, 20% test)
   - Standardized features using StandardScaler

2. **Model Training:**
   - Trained 6 different algorithms
   - Used stratified sampling for balanced classes
   - Applied cross-validation for robust evaluation

3. **Evaluation:**
   - Calculated 6 metrics per model
   - Generated confusion matrices
   - Compared model performances

## üîç Key Insights

### Best Model: **XGBoost**
- Highest overall performance across metrics
- Best accuracy (77.69%) and AUC (85.23%)
- Excellent balance between precision and recall
- Recommended for production use

### Runner-up: **Random Forest**
- Strong ensemble performance
- Good generalization with bagging
- Second-best MCC score (0.5169)

### Fastest: **Naive Bayes**
- Quickest training and prediction
- Suitable for real-time applications
- Good AUC despite lower accuracy

## üéØ Assignment Compliance

This project fulfills all requirements for **Machine Learning Assignment 2**:

- ‚úÖ Dataset with ‚â•12 features and ‚â•500 instances
- ‚úÖ 6 ML models implemented (Logistic Regression, Decision Tree, KNN, Naive Bayes, Random Forest, XGBoost)
- ‚úÖ 6 evaluation metrics calculated (Accuracy, AUC, Precision, Recall, F1, MCC)
- ‚úÖ Streamlit app with all required features:
  - CSV upload functionality
  - Model selection dropdown
  - Metrics display
  - Confusion matrix visualization
- ‚úÖ GitHub repository with proper structure
- ‚úÖ Deployed on Streamlit Community Cloud
- ‚úÖ Complete documentation

## üìù Technologies Used

- **Python 3.8+**
- **Streamlit** - Web application framework
- **Scikit-learn** - Machine learning algorithms
- **XGBoost** - Gradient boosting
- **Pandas** - Data manipulation
- **NumPy** - Numerical computing
- **Matplotlib & Seaborn** - Data visualization
- **Joblib** - Model persistence

## üë®‚Äçüíª Author

**M.Tech (AIML/DSE) Student**  
Work Integrated Learning Programmes Division  
BITS Pilani

## üìÑ License

This project is created for academic purposes as part of Machine Learning Assignment 2.

## üôè Acknowledgments

- BITS Pilani for providing the assignment framework
- Wine Quality Dataset contributors
- Streamlit community for excellent documentation

---

**Note:** This application is deployed on Streamlit Community Cloud's free tier. For production use with larger datasets, consider upgrading to a paid tier or deploying on a dedicated server.

## üìû Support

For issues or questions:
1. Check the [Streamlit Documentation](https://docs.streamlit.io)
2. Review the [Scikit-learn Documentation](https://scikit-learn.org)
3. Contact course instructor for assignment-related queries

---

**Last Updated:** February 2026  
**Version:** 1.0.0